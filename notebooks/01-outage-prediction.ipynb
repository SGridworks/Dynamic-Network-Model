{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "name": "01-outage-prediction.ipynb"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outage Prediction with Random Forest\n",
    "\n",
    "From the [Sisyphean Gridworks ML Playground](https://sgridworks.com/ml-playground/guides/01-outage-prediction.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Clone the repository and install dependencies. Run this cell first."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!git clone https://github.com/SGridworks/Dynamic-Network-Model.git 2>/dev/null || echo 'Already cloned'\n",
    "%cd Dynamic-Network-Model\n",
    "!pip install -q pandas numpy matplotlib seaborn scikit-learn xgboost lightgbm pyarrow"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "Open a new Jupyter notebook and run the following cell to import your libraries and load the three SP&L datasets. Run your code from the repository root (where the demo_data/ folder lives)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load SP&L datasets using the data loader API\n",
    "from demo_data.load_demo_data import (\n",
    "    load_outage_history, load_weather_data, load_transformers\n",
    ")\n",
    "\n",
    "outages      = load_outage_history()\n",
    "weather      = load_weather_data()\n",
    "transformers = load_transformers()\n",
    "\n",
    "print(f\"Outage events loaded: {len(outages):,}\")\n",
    "print(f\"Weather rows loaded:  {len(weather):,}\")\n",
    "print(f\"Transformers loaded:  {len(transformers):,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "\n",
    "Before building a model, look at what you have. Run each line below in its own cell so you can see the output."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# See the first few outage rows\n",
    "outages.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Daily Features\n",
    "\n",
    "Outages happen on a specific day. Weather is recorded every hour. To combine them, we need to summarize weather into daily statistics (max wind, max temperature, total rainfall, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# How many outages per cause code?\n",
    "outages[\"cause_code\"].value_counts().plot(kind=\"bar\", title=\"Outages by Cause\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Target Variable\n",
    "\n",
    "A classification model needs a target: the thing you are predicting. Our target is \"Did at least one outage happen on this day?\" (yes = 1, no = 0)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check the weather columns\n",
    "weather.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Time-Based Features\n",
    "\n",
    "Outages follow seasonal patterns. Let's add month-of-year and day-of-week as features so the model can learn these cycles."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a date column from the weather timestamp\n",
    "weather[\"date\"] = weather[\"timestamp\"].dt.date\n",
    "\n",
    "# Aggregate weather to daily summaries\n",
    "daily_weather = weather.groupby(\"date\").agg({\n",
    "    \"temperature_f\":   [\"max\", \"min\", \"mean\"],\n",
    "    \"wind_speed_mph\":  [\"max\", \"mean\"],\n",
    "    \"humidity_pct\":    \"mean\",\n",
    "    \"is_storm\":        \"max\",\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the multi-level column names\n",
    "daily_weather.columns = [\n",
    "    \"date\", \"temp_max\", \"temp_min\", \"temp_mean\",\n",
    "    \"wind_max\", \"wind_mean\", \"humidity_mean\", \"is_storm\"\n",
    "]\n",
    "\n",
    "print(daily_weather.head())\n",
    "print(f\"\\nDaily weather rows: {len(daily_weather)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Training and Test Sets\n",
    "\n",
    "We need to hold back some data the model has never seen, so we can honestly evaluate it later. The standard practice is an 80/20 split: 80% for training, 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract the date from each outage event\n",
    "outages[\"date\"] = outages[\"fault_detected\"].dt.date\n",
    "\n",
    "# Count outages per day\n",
    "outage_days = outages.groupby(\"date\").size().reset_index(name=\"outage_count\")\n",
    "\n",
    "# Merge with daily weather\n",
    "df = daily_weather.merge(outage_days, on=\"date\", how=\"left\")\n",
    "\n",
    "# Fill days with no outages as 0\n",
    "df[\"outage_count\"] = df[\"outage_count\"].fillna(0).astype(int)\n",
    "\n",
    "# Create the binary target: 1 if any outage, 0 if none\n",
    "df[\"outage_flag\"] = (df[\"outage_count\"] > 0).astype(int)\n",
    "\n",
    "print(f\"Total days: {len(df)}\")\n",
    "print(f\"Days with outages: {df['outage_flag'].sum()}\")\n",
    "print(f\"Days without outages: {(df['outage_flag'] == 0).sum()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Random Forest\n",
    "\n",
    "Now the exciting part. We create a Random Forest classifier and fit it on the training data. \"Fitting\" means the model examines all the training rows and learns patterns that connect weather features to outage outcomes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Convert date column to datetime for feature extraction\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# Add calendar features\n",
    "df[\"month\"]       = df[\"date\"].dt.month\n",
    "df[\"day_of_week\"] = df[\"date\"].dt.dayofweek    # 0 = Monday, 6 = Sunday\n",
    "df[\"is_summer\"]   = df[\"month\"].isin([6, 7, 8]).astype(int)\n",
    "\n",
    "print(df[[\"date\", \"temp_max\", \"wind_max\", \"month\", \"outage_flag\"]].head(10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model\n",
    "\n",
    "Now we use the held-out test data\u2014data the model has never seen\u2014to see how well it performs in the real world."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define features (X) and target (y)\n",
    "feature_cols = [\n",
    "    \"temp_max\", \"temp_min\", \"temp_mean\",\n",
    "    \"wind_max\", \"wind_mean\",\n",
    "    \"humidity_mean\", \"is_storm\",\n",
    "    \"month\", \"day_of_week\", \"is_summer\"\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[\"outage_flag\"]\n",
    "\n",
    "# Split: 80% train, 20% test (random_state for reproducibility)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples:     {len(X_test)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand Feature Importance\n",
    "\n",
    "One of the best things about Random Forests: they tell you which features matter most. This is valuable for utility engineers because it shows which weather variables drive outage risk."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create the model with 200 decision trees\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=200,       # number of trees in the forest\n",
    "    max_depth=10,           # limit tree depth to prevent overfitting\n",
    "    random_state=42,        # for reproducible results\n",
    "    class_weight=\"balanced\" # adjust for imbalanced classes\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training complete.\")\n",
    "print(f\"Number of trees: {model.n_estimators}\")\n",
    "print(f\"Features used:   {model.n_features_in_}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Built and Next Steps\n",
    "\n",
    "Congratulations. You just:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test, y_pred,\n",
    "      target_names=[\"No Outage\", \"Outage\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"No Outage\", \"Outage\"],\n",
    "            yticklabels=[\"No Outage\", \"Outage\"], ax=ax)\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"Actual\")\n",
    "ax.set_title(\"Confusion Matrix: Outage Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "feat_imp = pd.Series(importances, index=feature_cols).sort_values(ascending=True)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "feat_imp.plot(kind=\"barh\", color=\"#5FCCDB\", ax=ax)\n",
    "ax.set_title(\"Feature Importance: What Drives Outages?\")\n",
    "ax.set_xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}